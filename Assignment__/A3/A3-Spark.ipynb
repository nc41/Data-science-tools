{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T13:38:34.825959Z",
     "start_time": "2018-07-25T13:38:31.365463Z"
    }
   },
   "source": [
    "# Start Spark Context\n",
    "\n",
    "Make sure to execute first and execute only once per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the (small) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T15:51:19.406068Z",
     "start_time": "2018-07-25T15:51:19.317478Z"
    }
   },
   "outputs": [],
   "source": [
    "raw = sc.textFile('../data/rxSmallSubset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program that computes the total \"net ingredient cost\" of prescription items dispensed for each PERIOD in the data set (total pounds and pence from the NIC field).\n",
    "\n",
    "As you do this, be aware that this data (like all real data) can be quite noisy and dirty. The first line in the file might describe the schema, and so it doesnâ€™t have any valid data, just a bunch of text. You may or may not find lines that do not have enough entries on them, or where an entry is of the wrong type (for example, the NIC or ACT COST cannot be converted into a decimal number. Basically, you need to write robust code. If you find any error on a line, simply discard the line. Your code should still output the correct result.\n",
    "\n",
    "\n",
    "For your results, print out each period, in sorted order, followed by the total net ingredient cost for that period.\n",
    "\n",
    "The following steps are just a guide. Feel free to do it your own way.\n",
    "\n",
    "#### Define a function that checks if a string is a valid number and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from itertools import islice\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark import sql\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def clean_and_filter(df):\n",
    "\n",
    "    ## Converting to appropriate datatypes\n",
    "    df = df.withColumn('NIC', df['NIC'].cast('float'))\n",
    "    df = df.withColumn('BNF_CODE', df['BNF_CODE'].cast('string'))\n",
    "    df = df.withColumn('ITEMS', df['ITEMS'].cast('integer'))\n",
    "    df = df.withColumn('QUANTITY', df['QUANTITY'].cast('integer'))\n",
    "    df = df.withColumn('ACT_COST', df['ACT_COST'].cast('float'))\n",
    "    df = df.withColumn('SHA', df['SHA'].cast('string'))\n",
    "    df = df.withColumn('PCT', df['PCT'].cast('string'))\n",
    "    df = df.withColumn('PRACTICE', df['PRACTICE'].cast('string'))\n",
    "    df = df.withColumn('BNF_NAME', df['BNF_NAME'].cast('string'))\n",
    "    ## Dropping null rows\n",
    "    df = df.na.drop()\n",
    "    return df\n",
    "\n",
    "def convert_to_dataframe(data):\n",
    "    trans = data.map(lambda x: x.encode(\"ascii\", \"ignore\"))\n",
    "    tagsheader = trans.first()\n",
    "    header = sc.parallelize([tagsheader])\n",
    "    trans_data = trans.subtract(header)\n",
    "    tuple_data = trans_data.map(lambda x: tuple(str(x).split(\",\")))\n",
    "    df = tuple_data.toDF([\"SHA\",\"PCT\",\"PRACTICE\",\"BNF_CODE\",\"BNF_NAME\",\"ITEMS\",\"NIC\",\"ACT_COST\",\"QUANTITY\",\"PERIOD\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "raw_df = convert_to_dataframe(raw)\n",
    "\n",
    "raw_df = clean_and_filter(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the result in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|PERIOD|          sum(NIC)|\n",
      "+------+------------------+\n",
      "|201607|3563.1400191783905|\n",
      "|201608| 5234.559994220734|\n",
      "|201609|2747.1500222682953|\n",
      "|201610| 5375.820019602776|\n",
      "|201611|3918.3799645900726|\n",
      "|201612|4052.8500669002533|\n",
      "|201701| 3838.030029833317|\n",
      "|201702| 6235.619965791702|\n",
      "|201703| 3263.129995942116|\n",
      "|201704|7862.6200060248375|\n",
      "|201705|  5922.64001005888|\n",
      "|201706| 8012.429938673973|\n",
      "|201707| 6010.360013484955|\n",
      "|201708| 4226.469961047173|\n",
      "|201709| 4062.250020980835|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.groupBy(\"PERIOD\").agg(F.sum(\"NIC\")).orderBy('PERIOD').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 5 practices that issued the prescriptions with the highest total net ingredient cost in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T15:40:55.597184Z",
     "start_time": "2018-07-25T15:40:55.562379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|PRACTICE|          sum(NIC)|\n",
      "+--------+------------------+\n",
      "|  C81033|  4592.39990234375|\n",
      "|  P81772| 2573.469970703125|\n",
      "|  D82064|2070.1499996185303|\n",
      "|  D82048|  1241.31005859375|\n",
      "|  J82139| 1027.989990234375|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.groupBy(\"PRACTICE\").agg(F.sum(\"NIC\")).orderBy([\"sum(NIC)\"], ascending=[0]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to classify each sequence in the contaminated tardigrade file as being most likely bacteria or tardigrade.\n",
    "\n",
    "There are many ways to approach this job. Here are some steps at a high level:\n",
    "\n",
    "a) A function that calculates Edit Distance between two sequences\n",
    "\n",
    "b) Calculate Edit Distance for each sample against every clean and bacterial contig\n",
    "\n",
    "c) Find the shortest distance for each sample\n",
    "\n",
    "d) Classify samples\n",
    "\n",
    "You are likely to use much more RDD operations than previous tasks. Check documents for some handy functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-25T16:07:54.957924Z",
     "start_time": "2018-07-25T16:07:54.615578Z"
    }
   },
   "outputs": [],
   "source": [
    "bacterialRaw = sc.textFile('../data/exp1.oneline.fa.small')\n",
    "cleanRaw = sc.textFile('../data/nHd.2.3.abv500.oneline.fa.small')\n",
    "contaminatedRaw = sc.textFile('../data/LMYF01.1.oneline.fa.small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LMYF01000001.1', 'Bacteria'),\n",
       " ('LMYF01000002.1', 'Bacteria'),\n",
       " ('LMYF01000003.1', 'Clean'),\n",
       " ('LMYF01000004.1', 'Clean'),\n",
       " ('LMYF01000005.1', 'Bacteria'),\n",
       " ('LMYF01000006.1', 'Clean'),\n",
       " ('LMYF01000007.1', 'Not Sure'),\n",
       " ('LMYF01000008.1', 'Not Sure'),\n",
       " ('LMYF01000009.1', 'Not Sure'),\n",
       " ('LMYF01000010.1', 'Bacteria'),\n",
       " ('LMYF01000011.1', 'Bacteria'),\n",
       " ('LMYF01000012.1', 'Bacteria'),\n",
       " ('LMYF01000013.1', 'Clean'),\n",
       " ('LMYF01000014.1', 'Not Sure'),\n",
       " ('LMYF01000015.1', 'Clean'),\n",
       " ('LMYF01000016.1', 'Clean'),\n",
       " ('LMYF01000017.1', 'Bacteria'),\n",
       " ('LMYF01000018.1', 'Clean'),\n",
       " ('LMYF01000019.1', 'Bacteria'),\n",
       " ('LMYF01000020.1', 'Clean'),\n",
       " ('LMYF01000021.1', 'Clean'),\n",
       " ('LMYF01000022.1', 'Clean'),\n",
       " ('LMYF01000023.1', 'Bacteria'),\n",
       " ('LMYF01000024.1', 'Bacteria'),\n",
       " ('LMYF01000025.1', 'Bacteria'),\n",
       " ('LMYF01000026.1', 'Bacteria'),\n",
       " ('LMYF01000027.1', 'Not Sure'),\n",
       " ('LMYF01000028.1', 'Clean'),\n",
       " ('LMYF01000029.1', 'Bacteria'),\n",
       " ('LMYF01000030.1', 'Clean'),\n",
       " ('LMYF01000031.1', 'Bacteria'),\n",
       " ('LMYF01000032.1', 'Clean'),\n",
       " ('LMYF01000033.1', 'Clean'),\n",
       " ('LMYF01000034.1', 'Bacteria'),\n",
       " ('LMYF01000035.1', 'Bacteria'),\n",
       " ('LMYF01000036.1', 'Clean'),\n",
       " ('LMYF01000037.1', 'Clean'),\n",
       " ('LMYF01000038.1', 'Bacteria'),\n",
       " ('LMYF01000039.1', 'Clean'),\n",
       " ('LMYF01000040.1', 'Bacteria'),\n",
       " ('LMYF01000041.1', 'Clean'),\n",
       " ('LMYF01000042.1', 'Not Sure'),\n",
       " ('LMYF01000043.1', 'Bacteria'),\n",
       " ('LMYF01000044.1', 'Bacteria'),\n",
       " ('LMYF01000045.1', 'Not Sure'),\n",
       " ('LMYF01000046.1', 'Clean'),\n",
       " ('LMYF01000047.1', 'Clean'),\n",
       " ('LMYF01000048.1', 'Clean'),\n",
       " ('LMYF01000049.1', 'Clean'),\n",
       " ('LMYF01000050.1', 'Clean'),\n",
       " ('LMYF01000051.1', 'Clean'),\n",
       " ('LMYF01000052.1', 'Clean'),\n",
       " ('LMYF01000053.1', 'Bacteria'),\n",
       " ('LMYF01000054.1', 'Clean'),\n",
       " ('LMYF01000055.1', 'Clean'),\n",
       " ('LMYF01000056.1', 'Clean'),\n",
       " ('LMYF01000057.1', 'Clean'),\n",
       " ('LMYF01000058.1', 'Clean'),\n",
       " ('LMYF01000059.1', 'Clean'),\n",
       " ('LMYF01000060.1', 'Bacteria'),\n",
       " ('LMYF01000061.1', 'Bacteria'),\n",
       " ('LMYF01000062.1', 'Clean'),\n",
       " ('LMYF01000063.1', 'Clean'),\n",
       " ('LMYF01000064.1', 'Clean'),\n",
       " ('LMYF01000065.1', 'Not Sure'),\n",
       " ('LMYF01000066.1', 'Bacteria'),\n",
       " ('LMYF01000067.1', 'Bacteria'),\n",
       " ('LMYF01000068.1', 'Clean'),\n",
       " ('LMYF01000069.1', 'Bacteria'),\n",
       " ('LMYF01000070.1', 'Clean'),\n",
       " ('LMYF01000071.1', 'Clean'),\n",
       " ('LMYF01000072.1', 'Clean'),\n",
       " ('LMYF01000073.1', 'Clean'),\n",
       " ('LMYF01000074.1', 'Not Sure'),\n",
       " ('LMYF01000075.1', 'Clean'),\n",
       " ('LMYF01000076.1', 'Bacteria'),\n",
       " ('LMYF01000077.1', 'Clean'),\n",
       " ('LMYF01000078.1', 'Bacteria'),\n",
       " ('LMYF01000079.1', 'Clean'),\n",
       " ('LMYF01000080.1', 'Clean'),\n",
       " ('LMYF01000081.1', 'Clean'),\n",
       " ('LMYF01000082.1', 'Bacteria'),\n",
       " ('LMYF01000083.1', 'Bacteria'),\n",
       " ('LMYF01000084.1', 'Clean'),\n",
       " ('LMYF01000085.1', 'Clean'),\n",
       " ('LMYF01000086.1', 'Clean'),\n",
       " ('LMYF01000087.1', 'Clean'),\n",
       " ('LMYF01000088.1', 'Clean'),\n",
       " ('LMYF01000089.1', 'Clean'),\n",
       " ('LMYF01000090.1', 'Bacteria'),\n",
       " ('LMYF01000091.1', 'Clean'),\n",
       " ('LMYF01000092.1', 'Bacteria'),\n",
       " ('LMYF01000093.1', 'Clean'),\n",
       " ('LMYF01000094.1', 'Not Sure'),\n",
       " ('LMYF01000095.1', 'Bacteria'),\n",
       " ('LMYF01000096.1', 'Bacteria'),\n",
       " ('LMYF01000097.1', 'Clean'),\n",
       " ('LMYF01000098.1', 'Not Sure'),\n",
       " ('LMYF01000099.1', 'Clean'),\n",
       " ('LMYF01000100.1', 'Bacteria')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# myRDDlist = [bacterialRaw,cleanRaw,contaminatedRaw]\n",
    "\n",
    "def checkSequence(l1, l2):\n",
    "    x = 0\n",
    "    check = \"ACTG\"\n",
    "   \n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] not in check or l2[i] not in check:\n",
    "            return float('inf')\n",
    "        \n",
    "        if l1[i] != l2[i]:\n",
    "            x += 1\n",
    "            \n",
    "    return x\n",
    "\n",
    "def Func(lines):\n",
    "    lines = lines.split('|')\n",
    "    return lines\n",
    "\n",
    "line = contaminatedRaw.map(lambda s: s.replace(\">\",\"\").replace(\"<\",\"|\"))\n",
    "line = line.map(Func)\n",
    "line.take(100)\n",
    "sample_list = line.collect()\n",
    "# print(sample_list)\n",
    "\n",
    "ba = bacterialRaw.map(lambda s: s.replace(\">\",\"\").replace(\"<\",\"|\"))\n",
    "ba = ba.map(Func)\n",
    "# ba.take(10)\n",
    "Ba_list = ba.collect()\n",
    "\n",
    "clean = cleanRaw.map(lambda s: s.replace(\">\",\"\").replace(\"<\",\"|\"))\n",
    "clean = clean.map(Func)\n",
    "clean_list = clean.collect()\n",
    "\n",
    "\n",
    "# clean.take(10)\n",
    "clean_dist = []\n",
    "ba_dist = []\n",
    "\n",
    "for s in sample_list:\n",
    "    t = []\n",
    "    for c in clean_list:\n",
    "        t.append(checkSequence(s[2], c[2]))\n",
    "    \n",
    "    clean_dist.append(t)\n",
    "\n",
    "# print(clean_dist)\n",
    "\n",
    "for s in sample_list:\n",
    "    t = []\n",
    "    for b in Ba_list:\n",
    "        t.append(checkSequence(s[2], b[2]))\n",
    "    \n",
    "    ba_dist.append(t)\n",
    "    \n",
    "# print(ba_dist)\n",
    "\n",
    "min_clean = [min(c) for c in clean_dist]\n",
    "# print(min_clean)\n",
    "\n",
    "min_ba = [min(b) for b in ba_dist]\n",
    "# print(min_ba)\n",
    "\n",
    "import collections\n",
    "\n",
    "res = []\n",
    "sample_name = [s[1].split()[0] for s in sample_list]\n",
    "for i in range(len(min_clean)):\n",
    "    if min_clean[i] < min_ba[i]:\n",
    "        res.append((sample_name[i], 'Clean'))\n",
    "    elif min_clean[i] > min_ba[i]:\n",
    "        res.append((sample_name[i], 'Bacteria'))\n",
    "    else:\n",
    "        t1 = collections.Counter(clean_dist[i])\n",
    "        t2 = collections.Counter(ba_dist[i])\n",
    "        if t1[min_clean[i]] > t2[min_ba[i]]:\n",
    "            res.append((sample_name[i], 'Clean'))\n",
    "        elif t1[min_clean[i]] < t2[min_ba[i]]:\n",
    "            res.append((sample_name[i],'Bacteria'))\n",
    "        else:\n",
    "            res.append((sample_name[i],'Not Sure'))\n",
    "# print(res)\n",
    "\n",
    "res_rdd = sc.parallelize(res)\n",
    "res_rdd.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rdd.filter(lambda x : x[1] == 'Bacteria').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
