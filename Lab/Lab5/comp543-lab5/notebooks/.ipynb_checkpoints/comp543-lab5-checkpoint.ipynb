{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code sets up the \"Spark Context\" which is how we interact with Spark from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWords (fileName):\n",
    "    textfile = sc.textFile(fileName)\n",
    "    lines = textfile.flatMap(lambda line: line.split(\" \"))\n",
    "    counts = lines.map (lambda word: (word, 1))\n",
    "    aggregatedCounts = counts.reduceByKey (lambda a, b: a + b)\n",
    "    return aggregatedCounts.top (200, key=lambda p : p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 38650),\n",
       " ('the', 7562),\n",
       " ('to', 5275),\n",
       " ('a', 4911),\n",
       " ('and', 4646),\n",
       " ('of', 4458),\n",
       " ('is', 3257),\n",
       " ('I', 2900),\n",
       " ('for', 2883),\n",
       " ('in', 2648),\n",
       " ('that', 1781),\n",
       " ('you', 1746),\n",
       " ('on', 1631),\n",
       " ('it', 1523),\n",
       " ('be', 1461),\n",
       " ('with', 1419),\n",
       " ('or', 1352),\n",
       " ('have', 1231),\n",
       " ('are', 1212),\n",
       " ('The', 1169),\n",
       " ('can', 1093),\n",
       " ('From:', 1065),\n",
       " ('this', 1060),\n",
       " ('from', 1035),\n",
       " ('as', 1029),\n",
       " ('Subject:', 1020),\n",
       " ('Date:', 1012),\n",
       " ('Lines:', 1002),\n",
       " ('<doc', 1000),\n",
       " ('url=\"\"', 1000),\n",
       " ('</doc>', 1000),\n",
       " ('Apr', 902),\n",
       " ('GMT', 868),\n",
       " ('-', 860),\n",
       " ('image', 844),\n",
       " ('an', 818),\n",
       " ('not', 814),\n",
       " ('but', 800),\n",
       " ('will', 772),\n",
       " ('by', 758),\n",
       " ('at', 750),\n",
       " ('1993', 732),\n",
       " ('if', 637),\n",
       " ('about', 583),\n",
       " ('would', 581),\n",
       " ('any', 574),\n",
       " ('|', 566),\n",
       " ('some', 540),\n",
       " ('JPEG', 530),\n",
       " ('file', 517),\n",
       " ('If', 515),\n",
       " ('has', 512),\n",
       " ('do', 509),\n",
       " ('which', 493),\n",
       " ('In', 476),\n",
       " ('It', 475),\n",
       " ('Re:', 473),\n",
       " ('This', 461),\n",
       " ('other', 445),\n",
       " ('was', 443),\n",
       " ('there', 427),\n",
       " ('use', 427),\n",
       " ('all', 427),\n",
       " ('get', 424),\n",
       " ('like', 422),\n",
       " ('your', 420),\n",
       " ('also', 413),\n",
       " ('more', 409),\n",
       " ('so', 395),\n",
       " ('=', 393),\n",
       " ('my', 391),\n",
       " ('writes:', 384),\n",
       " ('one', 377),\n",
       " ('available', 369),\n",
       " ('images', 369),\n",
       " ('out', 368),\n",
       " ('know', 367),\n",
       " ('me', 365),\n",
       " ('than', 354),\n",
       " ('article', 351),\n",
       " ('program', 350),\n",
       " ('93', 348),\n",
       " ('graphics', 343),\n",
       " (\"don't\", 342),\n",
       " ('what', 335),\n",
       " (':', 330),\n",
       " ('data', 325),\n",
       " ('A', 307),\n",
       " ('need', 306),\n",
       " ('only', 297),\n",
       " ('software', 295),\n",
       " ('just', 291),\n",
       " ('am', 291),\n",
       " ('files', 290),\n",
       " ('version', 289),\n",
       " (\"I'm\", 288),\n",
       " ('color', 279),\n",
       " ('very', 275),\n",
       " ('bit', 269),\n",
       " ('Graphics', 269),\n",
       " ('anyone', 266),\n",
       " ('using', 260),\n",
       " ('find', 255),\n",
       " ('they', 251),\n",
       " ('You', 250),\n",
       " ('GIF', 250),\n",
       " ('does', 249),\n",
       " ('format', 246),\n",
       " ('into', 246),\n",
       " ('3D', 244),\n",
       " ('display', 241),\n",
       " ('been', 237),\n",
       " ('no', 229),\n",
       " ('much', 225),\n",
       " ('For', 222),\n",
       " ('want', 222),\n",
       " ('information', 218),\n",
       " ('many', 218),\n",
       " ('how', 217),\n",
       " ('then', 215),\n",
       " ('may', 214),\n",
       " ('could', 213),\n",
       " ('should', 210),\n",
       " ('up', 207),\n",
       " ('package', 207),\n",
       " (\"it's\", 207),\n",
       " ('these', 205),\n",
       " ('good', 205),\n",
       " ('such', 205),\n",
       " ('24', 203),\n",
       " ('where', 202),\n",
       " ('send', 201),\n",
       " ('free', 198),\n",
       " ('code', 197),\n",
       " ('There', 196),\n",
       " ('looking', 195),\n",
       " ('we', 193),\n",
       " ('their', 191),\n",
       " ('May', 188),\n",
       " ('used', 188),\n",
       " ('them', 188),\n",
       " (\"I've\", 183),\n",
       " ('number', 183),\n",
       " ('when', 178),\n",
       " ('help', 177),\n",
       " ('see', 177),\n",
       " ('programs', 176),\n",
       " ('Computer', 176),\n",
       " ('Distribution:', 175),\n",
       " ('University', 175),\n",
       " ('two', 173),\n",
       " ('line', 173),\n",
       " ('make', 172),\n",
       " ('--', 171),\n",
       " ('&', 170),\n",
       " ('system', 168),\n",
       " ('its', 168),\n",
       " ('What', 167),\n",
       " ('it.', 165),\n",
       " ('who', 164),\n",
       " (',', 163),\n",
       " ('FTP', 162),\n",
       " ('Thanks', 160),\n",
       " ('think', 159),\n",
       " ('o', 159),\n",
       " ('2', 158),\n",
       " ('16', 157),\n",
       " ('Image', 156),\n",
       " ('Please', 153),\n",
       " ('convert', 152),\n",
       " ('time', 152),\n",
       " ('same', 152),\n",
       " ('point', 151),\n",
       " ('most', 151),\n",
       " ('people', 151),\n",
       " ('video', 150),\n",
       " ('Does', 150),\n",
       " ('mail', 149),\n",
       " ('different', 146),\n",
       " ('*', 146),\n",
       " ('support', 146),\n",
       " ('computer', 146),\n",
       " ('world', 145),\n",
       " ('please', 145),\n",
       " ('problem', 145),\n",
       " ('those', 144),\n",
       " ('We', 144),\n",
       " ('work', 142),\n",
       " ('quality', 141),\n",
       " ('read', 141),\n",
       " ('under', 139),\n",
       " ('etc.', 138),\n",
       " ('better', 136),\n",
       " ('even', 135),\n",
       " (\"It's\", 135),\n",
       " ('well', 134),\n",
       " ('via', 133),\n",
       " ('new', 133),\n",
       " ('Any', 132),\n",
       " ('processing', 132)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countWords(\"../data/20-news-same-line-small.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing a Spark Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# load up all of the 19997 documents in the corpus\n",
    "corpus = sc.textFile (\"../data/20-news-same-line-small.txt\")\n",
    "\n",
    "# each entry in validLines will be a line from the text file\n",
    "validLines = corpus.filter(lambda x : 'id' in x)\n",
    "\n",
    "# now we transform it into a bunch of (docID, text) pairs\n",
    "keyAndText = validLines.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:]))\n",
    "\n",
    "# now we split the text in each (docID, text) pair into a list of words\n",
    "# after this, we have a data set with (docID, [\"word1\", \"word2\", \"word3\", ...])\n",
    "# we have a bit of fancy regular expression stuff here to make sure that we do not\n",
    "# die on some of the documents\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "keyAndListOfWords = keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', x[1]).lower().split()))\n",
    "\n",
    "# now get the top 20,000 words... first change (docID, [\"word1\", \"word2\", \"word3\", ...])\n",
    "# to (\"word1\", 1) (\"word2\", 1)...\n",
    "allWords = keyAndListOfWords.flatMap(lambda x: ((j, 1) for j in x[1]))\n",
    "\n",
    "# now, count all of the words, giving us (\"word1\", 1433), (\"word2\", 3423423), etc.\n",
    "allCounts = allWords.reduceByKey (lambda a, b: a + b)\n",
    "\n",
    "# and get the top 20,000 words in a local array\n",
    "# each entry is a (\"word1\", count) pair\n",
    "topWords = allCounts.top (20000, lambda x : x[1])\n",
    "\n",
    "# and we'll create a RDD that has a bunch of (word, dictNum) pairs\n",
    "# start by creating an RDD that has the number 0 thru 20000\n",
    "# 20000 is the number of words that will be in our dictionary\n",
    "twentyK = sc.parallelize(range(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Code Here\n",
    "\n",
    "Your task is to map the parallelized range $(0, 1, 2, \\ldots, )$ \n",
    "into a set of tuples (\"mostcommonword\", 0), (\"nextmostcommon\", 1), ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zyxel', 4580),\n",
       " ('zyeh', 2058),\n",
       " ('zyda', 2698),\n",
       " ('zvi', 9584),\n",
       " ('zurich', 8040),\n",
       " ('zug', 8075),\n",
       " ('zorg', 4647),\n",
       " ('zopfi', 8548),\n",
       " ('zooming', 2994),\n",
       " ('zoom', 2193)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, we transform (0), (1), (2), ... to (\"mostcommonword\", 0) (\"nextmostcommon\", 1), ...\n",
    "# the number will be the spot in the dictionary used to tell us where the word is located\n",
    "# HINT: make use of topWords in the lambda that you supply\n",
    "dictionary = twentyK.map(lambda x : (topWords[x][0], x) )\n",
    "\n",
    "# finally, print out some of the dictionary, just for debugging\n",
    "dictionary.top (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
